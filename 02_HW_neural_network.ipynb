{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "pgrdJ1tvB8GM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.\n",
        "Hàm softmax dùng exponential function (e) mà không phải số khác như 2, 3 hoặc 4:\n",
        "do $e^x$ đạo hàm được và có đạo hàm đẹp hơn các số tự nhiên ($=e^x$)"
      ],
      "metadata": {
        "id": "3R8HiJ6WTPrK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.\n",
        "Cho bài toán XOR,\n",
        "\n",
        "Implement thuật toán neural network để giải bài toán\n"
      ],
      "metadata": {
        "id": "6cI3hJXTCl_t"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgpTS2rzjCS6"
      },
      "source": [
        "import torch.nn as nn\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXEXUNbYjKdi"
      },
      "source": [
        "# create data\n",
        "X = torch.Tensor([[0., 0.],\n",
        "               [0., 1.],\n",
        "               [1., 0.],\n",
        "               [1., 1.]])\n",
        "\n",
        "y = torch.Tensor([0., 1., 1., 0.]).reshape(X.shape[0], 1)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xj9aWn_7jMCv"
      },
      "source": [
        "class XOR(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(XOR, self).__init__()\n",
        "        self.linear = nn.Linear(2, 2)\n",
        "        self.Sigmoid = nn.Sigmoid()\n",
        "        self.linear2 = nn.Linear(2, 1)\n",
        "\n",
        "    def forward(self, input):\n",
        "      x = self.linear(input)\n",
        "      sig = self.Sigmoid(x)\n",
        "      yh = self.linear2(sig)\n",
        "      return yh"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3f1Xs2TcjOCI"
      },
      "source": [
        "xor_network = XOR()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82Adr85ZjQ17"
      },
      "source": [
        "epochs = 1000\n",
        "mseloss = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(xor_network.parameters(), lr = 0.03)\n",
        "all_losses = []\n",
        "current_loss = 0\n",
        "plot_every = 50\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "  # input training example and return the prediction\n",
        "  yhat = xor_network.forward(X)\n",
        "\n",
        "  # calculate MSE loss\n",
        "  loss = mseloss(yhat, y)\n",
        "\n",
        "  # backpropogate through the loss gradiants\n",
        "  loss.backward()\n",
        "\n",
        "  # update model weights\n",
        "  optimizer.step()\n",
        "\n",
        "  # remove current gradients for next iteration\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  # append to loss\n",
        "  current_loss += loss\n",
        "  if epoch % plot_every == 0:\n",
        "      all_losses.append(current_loss / plot_every)\n",
        "      current_loss = 0\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHRQVH_6jUWd",
        "outputId": "19b8717c-32a3-42c8-a733-9db785552e2a"
      },
      "source": [
        "# show weights and bias\n",
        "for name, param in xor_network.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(name, param.data)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "linear.weight tensor([[-5.2789, -5.2308],\n",
            "        [-2.7595, -2.7551]])\n",
            "linear.bias tensor([1.3233, 3.4728])\n",
            "linear2.weight tensor([[-2.0202,  1.8657]])\n",
            "linear2.bias tensor([-0.2141])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RB_Y0q_VjWAP",
        "outputId": "bb6e6adb-963d-4e7a-ac7e-028599d175d9"
      },
      "source": [
        "# test input\n",
        "input = torch.tensor([1., 1.])\n",
        "out = xor_network(input)\n",
        "print(out.round())\n",
        "\n",
        "input = torch.tensor([0., 0.])\n",
        "out = xor_network(input)\n",
        "print(out.round())"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.], grad_fn=<RoundBackward0>)\n",
            "tensor([0.], grad_fn=<RoundBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Dataset MNIST\n",
        "- Implement thuật toán neural network với dữ liệu trên sử dụng Pytorch\n",
        "- Chỉnh learning rate, vẽ đồ thị loss tương ứng.\n",
        "- Chia tập train/test tỉ lệ 80/20, tính các chỉ số accuracy, recall, f1-score trên tập test."
      ],
      "metadata": {
        "id": "36SJ_KPmWrHv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8VKpZpaTWrp0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}